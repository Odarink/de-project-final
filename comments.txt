###Шаг 1. Изучение входных данных.
Источник для загрузки данных буду использовать postgres.
Настроил подключение в python и IDE.
Сделал тестовые селекты заданных в проекте таблиц.

Шаг 2. Создание таблиц для хранилища.
Подключился к Vertica.
Воссоздал структура данных as is в Vertica stg_currencies и stg_transactions.
Написал скрипт для переноса данных, где использовал pydantic (BaseModel) для того, чтобы задать модель данных
на считывание и хранить строку как обьект. Смог считать с postgre преобразовать в BaseModel и залить в Vertica
при помощи скрипта. Однако при переносе на тест ДАГ, возникла проблема, что в контейнере с Airflow не установлена
библиотека pydantic... (Оставлю скрипт в dags/stg/raw_pydantic_stg_load_from_postgres.py)
Пришлось переработать скрипт.
UPD: поздно подумал о том чтоб в docker terminal просто pip install сделать, так что дальше все без BaseModel.
Создал 3 таблицы, схемы создания (ddl) лежат в sql/*
Все сделал по заданию хеширование, сортировка и партицирование.
Настроил connections + variables в среде airflow, чтоб тянуть в Даг.

Шаг 3. Пайплайн загрузки данных из систем-источников в staging-слой
Сделал catchup = True и задал рамки в диапазоне октября 2022 года чтоб расчет был только за этот месяц и с
инкрементальной загрузкой.
Если данные уже есть в таблице за этот день, то они перезапишутся, а не дублицируется.
Запустил даг проверил что данные поступают. Пофиксил все мелкие ошибки. dags/stg/*

Шаг 4. Пайплайн обновления витрины данных
Составил скрипт для заполнения таблицы global_metrics с учетом всех фильтров:
                    WHERE date_update::date = '{date}'
                        AND account_number_from > 0
                        AND account_number_to > 0
                        AND status = 'done'
                        AND transaction_type IN ('c2a_incoming',
                                                    'c2b_partner_incoming',
                                                    'sbp_incoming',
                                                    'sbp_outgoing',
                                                    'transfer_incoming',
                                                    'transfer_outgoing')
проверил select и начала разработку таски в Airflow.
Составил dag в dags/dds/* и протестировал его работу.
Запустил инкерментальную загрузку за октябрь 2022 года как в стейджинге.

Шаг 5. Создание дашборда
Зашел в Metadata составил тестовые дашборды без фильтров по валюте (стране).
Добавил дашборд с фильтром без России.
